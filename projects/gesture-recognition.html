<!DOCTYPE html>
<html lang="en" data-theme="light">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <meta name="description" content="Real-Time Hand Gesture Recognition — Antoine Besson" />
  <title>Hand Gesture Recognition | Antoine Besson</title>
  <link rel="stylesheet" href="../style.css" />
  <link rel="preconnect" href="https://fonts.googleapis.com" />
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin />
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&display=swap" rel="stylesheet" />
</head>
<body>

  <!-- Minimal navbar with back link + theme toggle -->
  <header class="navbar" id="navbar">
    <div class="navbar__container">
      <a href="../index.html" class="navbar__logo">&larr; Back</a>
      <div class="navbar__actions">
        <button class="theme-toggle" id="themeToggle" aria-label="Toggle dark mode">
          <svg class="icon icon--sun" xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24"
               fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round">
            <circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/>
            <line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/>
            <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/>
            <line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/>
            <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/>
          </svg>
          <svg class="icon icon--moon" xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24"
               fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round">
            <path d="M21 12.79A9 9 0 1 1 11.21 3a7 7 0 0 0 9.79 9.79z"/>
          </svg>
        </button>
      </div>
    </div>
  </header>

  <main class="project-detail">
    <div class="project-detail__container">

      <div class="project-detail__tags">
        <span class="tag">PyTorch</span>
        <span class="tag">MediaPipe</span>
        <span class="tag">OpenCV</span>
      </div>

      <h1 class="project-detail__title">Real-Time Hand Gesture Recognition</h1>

      <p class="project-detail__intro">
        A lightweight deep-learning pipeline that classifies hand gestures in real time
        directly on CPU, suitable for interactive applications and accessibility tools.
      </p>

      <!-- ——— Customise the sections below ——— -->

      <section class="project-detail__section">
        <h2>Overview</h2>
        <p>
          The system extracts 21 hand landmarks using MediaPipe, normalises them into a
          feature vector, and feeds them into a compact CNN trained with PyTorch. An OpenCV
          pipeline handles video capture, overlay rendering, and frame-rate management.
        </p>
      </section>

      <section class="project-detail__section">
        <h2>Key Achievements</h2>
        <ul>
          <li><strong>93.6 % classification accuracy</strong> on a custom gesture dataset with a compact CNN architecture.</li>
          <li><strong>Real-time CPU inference &lt; 10 ms</strong> per frame, enabling smooth 30+ FPS live demos.</li>
          <li>End-to-end OpenCV pipeline for live webcam capture, data collection, and visual feedback.</li>
        </ul>
      </section>

      <section class="project-detail__section">
        <h2>Model Architecture</h2>
        <p>
          <!-- Customise: describe your model layers, input shape, training details -->
          The classifier is a three-layer 1-D CNN operating on the 63-dimensional landmark
          vector (21 points &times; 3 coordinates). Batch normalisation and dropout are used
          between layers. Training was performed for 50 epochs with an Adam optimiser and
          a cosine-annealing learning rate schedule.
        </p>
      </section>

      <section class="project-detail__section">
        <h2>Lessons Learned</h2>
        <p>
          <!-- Customise: reflect on challenges and takeaways -->
          Landmark normalisation relative to the wrist was the single most impactful
          preprocessing step — it made the model invariant to hand position and distance
          from the camera, improving generalisation across users.
        </p>
      </section>

    </div>
  </main>

  <footer class="footer">
    <div class="footer__container">
      <p class="footer__copy">&copy; 2026 Antoine Besson</p>
    </div>
  </footer>

  <script src="../script.js"></script>
</body>
</html>
